# -*- coding: utf-8 -*-
"""Computer Vision with YOLO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oRp8ae2wzF4w5KEosCkJO-LDCxrOD9eF
"""

'''
This notebook is a submission to the zindi crop detection challenge. The aim of the challenge is to predict the
type of disease affecting a crop using YOLO (You Only Look Once) model.
'''

# Commented out IPython magic to ensure Python compatibility.
#import required libraries
import requests
from PIL import Image
from zipfile import ZipFile
import os
import shutil
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#install YOLOv5
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5
# %pip install -qr requirements.txt

# Add the yolov5 directory to the Python path
import sys
sys.path.append('/content/yolov5')


#import YOLO and Torch
import torch
from yolov5.models.yolo import Model as YOLOv5 # Import YOLOv5 from the correct location

#check if GPU is available
print(f'GPU Available: {torch.cuda.is_available()}')

'''
We have added YOLO and checked our GPU availability. Next we will see how we can read the images from the drive,
Convert the annotated data into YOLO format, train and make predictions.
'''

"""#Set Kaggle API & Download Dataset"""

from google.colab import files
files.upload()  # This will prompt you to upload the kaggle.json file

# Create a Kaggle directory
os.makedirs('/root/.kaggle', exist_ok=True)

# Move the kaggle.json file to the appropriate location
!cp kaggle.json /root/.kaggle/

# Set permissions for the kaggle.json file
!chmod 600 /root/.kaggle/kaggle.json

# Download the dataset
!kaggle datasets download -d ohagwucollinspatrick/ghana-crop-disease

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Upload the dataset
!mv ghana-crop-disease.zip /content/drive/MyDrive/

'''
The dataset has been downloaded and uploaded to google drive. Run the above cells to get the dataset.
Run the cells below to continue the project.
'''

"""#Data Preprocessing and Label Annotation"""

# Load the annotation csv
train = pd.read_csv('/content/drive/MyDrive/zindi_train.csv')

# Check the data
train.head()

# Check the number of unique classes
train['class'].nunique()

'''
There are 23 different annotated classes indicating there are 23 different diseases identified from the images.
The ymin, ymax, xmin, xmax are the positions of the various bouding boxes around the disease.
We will need to convert the train set to YOLO format. The following preprocessing steps will take place:
1. Perform data validation to ensure features are of the correct data type.
2. We will convert the values under the class column to numeric
3. We will scale values of ymin, ymax, xmin, xmax
'''

# Check the data
train.info()

'''
The data is very clean and there are no missing values and the data types are correct.
'''

# Convert class to numeric
le = LabelEncoder()
train['class'] = le.fit_transform(train['class'])

# Check the class column
train['class'].unique()

# Define the Image dimensions
image_width = 640
image_height = 640

# Directory to save YOLO annotations
output_dir = '/content/dataset/labels'
os.makedirs(output_dir, exist_ok=True)

# Convert the data into YOLO format
for index, row in train.iterrows():
  image_name = row['image_id'].replace('.jpg', '')
  class_id = row['class']
  xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']

  # Calculate the center coordinates and dimensions
  x_center = ((xmax + xmin) / 2) / image_width
  y_center = ((ymax + ymin) / 2) / image_height
  width = (xmax - xmin) / image_width
  height = (ymax - ymin) / image_height