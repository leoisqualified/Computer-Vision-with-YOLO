{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUS2kDo2wu/2bdJObo2JNe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoisqualified/Computer-Vision-with-YOLO/blob/main/Computer_Vision_with_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LWAOEHc6hvnq",
        "outputId": "56c4a857-4905-4d7a-f2d3-645516dab5a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThis notebook is a submission to the zindi crop detection challenge. The aim of the challenge is to predict the\\ntype of disease affecting a crop using YOLO (You Only Look Once) model.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "This notebook is a submission to the zindi crop detection challenge. The aim of the challenge is to predict the\n",
        "type of disease affecting a crop using YOLO (You Only Look Once) model.\n",
        "'''"
      ]
    },
    {
      "source": [
        "#import required libraries\n",
        "import requests\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "#install YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "# Add the yolov5 directory to the Python path\n",
        "import sys\n",
        "sys.path.append('/content/yolov5')\n",
        "\n",
        "#check if GPU is available\n",
        "print(f'GPU Available: {torch.cuda.is_available()}')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPpTrXvalqWO",
        "outputId": "f57597b0-37c2-44b5-fb42-8bd96eb09308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16995, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 16995 (delta 101), reused 114 (delta 53), pack-reused 16805 (from 1)\u001b[K\n",
            "Receiving objects: 100% (16995/16995), 15.72 MiB | 13.79 MiB/s, done.\n",
            "Resolving deltas: 100% (11630/11630), done.\n",
            "/content/yolov5\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m870.5/870.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "GPU Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "We have added YOLO and checked our GPU availability. Next we will see how we can read the images from the drive,\n",
        "Convert the annotated data into YOLO format, train and make predictions.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UDuKT79loWNl",
        "outputId": "0b287e77-2b49-4a0c-cd9e-071ec28228cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe have added YOLO and checked our GPU availability. Next we will see how we can read the images from the drive,\\nConvert the annotated data into YOLO format, train and make predictions.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Kaggle API & Download Dataset"
      ],
      "metadata": {
        "id": "aUQP9JA_bDrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#files.upload()   This will prompt you to upload the kaggle.json file"
      ],
      "metadata": {
        "id": "pozlRpqBmH4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Kaggle directory\n",
        "#os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Move the kaggle.json file to the appropriate location\n",
        "#!cp kaggle.json /root/.kaggle/\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "#!chmod 600 /root/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "UyHE_xgubCfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "#!kaggle datasets download -d ohagwucollinspatrick/ghana-crop-disease"
      ],
      "metadata": {
        "id": "7ENkQsU0dwg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4J1bQKkvfjjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the dataset\n",
        "#!mv ghana-crop-disease.zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "Rs-ogkT3fxYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The dataset has been downloaded and uploaded to google drive. Run the above cells to get the dataset.\n",
        "Run the cells below to continue the project.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "H1l6L7UqgIlI",
        "outputId": "1582b077-e815-442e-d0dc-1424a2d77266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe dataset has been downloaded and uploaded to google drive. Run the above cells to get the dataset.\\nRun the cells below to continue the project.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCT2jK6tT-gI",
        "outputId": "e8425c87-99e7-4d60-c059-d66fb1dcc6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing and Validation"
      ],
      "metadata": {
        "id": "I7jtECAoi_PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the annotation csv\n",
        "train = pd.read_csv('/content/drive/MyDrive/zindi_train.csv')\n",
        "\n",
        "# Check the data\n",
        "train.head()"
      ],
      "metadata": {
        "id": "rA7NVUxFjQFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of unique classes\n",
        "train['class'].nunique()"
      ],
      "metadata": {
        "id": "BeIIc01ytm8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "There are 23 different annotated classes indicating there are 23 different diseases identified from the images.\n",
        "The ymin, ymax, xmin, xmax are the positions of the various bouding boxes around the disease.\n",
        "We will need to convert the train set to YOLO format. The following preprocessing steps will take place:\n",
        "1. Perform data validation to ensure features are of the correct data type.\n",
        "2. We will convert the values under the class column to numeric\n",
        "3. We will scale values of ymin, ymax, xmin, xmax\n",
        "'''"
      ],
      "metadata": {
        "id": "vYTrME3QtsLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data\n",
        "train.info()"
      ],
      "metadata": {
        "id": "N3S_414ezHQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The data is very clean and there are no missing values and the data types are correct.\n",
        "'''"
      ],
      "metadata": {
        "id": "F6IzwdcbzN99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create YOLO Format Annotation for Train"
      ],
      "metadata": {
        "id": "jFCSZESbahNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert class to numeric\n",
        "le = LabelEncoder()\n",
        "train['class'] = le.fit_transform(train['class'])\n",
        "\n",
        "# Check the class column\n",
        "train['class'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "i--LDRAl0mHm",
        "outputId": "aa7a39ba-7727-4bfd-a33d-991ad1ac68dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3b2053a348d7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert class to numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check the class column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Image dimensions (you might want to adjust this based on your actual image dimensions)\n",
        "image_width = 640\n",
        "image_height = 640\n",
        "\n",
        "# Directory to save YOLO annotations\n",
        "output_dir = '/content/dataset/labels/train'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convert the data into YOLO format\n",
        "for index, row in train.iterrows():\n",
        "    # Extract relevant data from each row\n",
        "    image_name = row['Image_ID'].replace('.jpg', '')  # Image name without extension\n",
        "    class_id = row['class']  # The class/category ID\n",
        "    xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']  # Bounding box coordinates\n",
        "\n",
        "    # Calculate the center coordinates and dimensions in YOLO format (normalized)\n",
        "    x_center = ((xmax + xmin) / 2) / image_width\n",
        "    y_center = ((ymax + ymin) / 2) / image_height\n",
        "    width = (xmax - xmin) / image_width\n",
        "    height = (ymax - ymin) / image_height\n",
        "\n",
        "    # Create a corresponding annotation file for each image\n",
        "    train_yolo_annotation_file = os.path.join(output_dir, f'{image_name}.txt')\n",
        "\n",
        "    # Write the annotation to the file\n",
        "    with open(train_yolo_annotation_file, 'a') as f:\n",
        "        f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")"
      ],
      "metadata": {
        "id": "Oh4zaGsC2NOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read the Images from the Dataset"
      ],
      "metadata": {
        "id": "U315FZiadxZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to image\n",
        "source_path = '/content/drive/MyDrive/ghana-crop-disease.zip'\n",
        "\n",
        "#Destination Path\n",
        "extraction_path = '/content/dataset/'\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "#Read images\n",
        "with ZipFile(source_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extraction_path)\n",
        "  #Output if extraction is done\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9YZgHGda-VG",
        "outputId": "4075ce3a-4572-499b-e05b-a1de7e04d6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "After extracting delete the submission file test and train from the dataset folder.\n",
        "These are redundant files\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d0VHY5Lglna8",
        "outputId": "fb996dca-d5db-425d-9cbe-d1cd5969d08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAfter extracting delete the submission file test and train from the dataset folder.\\nThese are redundant files\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating and Organizing the Directory for YOLOv5"
      ],
      "metadata": {
        "id": "DgKrh4WOmwT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "From the above cells we have created the YOLO format for the test annotations created and have extracted the images\n",
        "File. Now we will create directories and prepare it for the YOLOv5 model.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xKCyb8hoeNZ_",
        "outputId": "a1e802b9-e721-42b0-bc86-2f991def840a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFrom the above cells we have created the YOLO format for the test annotations created and have extracted the images \\nFile. Now we will create directories and prepare it for the YOLOv5 model.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcED3unBoy8v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}